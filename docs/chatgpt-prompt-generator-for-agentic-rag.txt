I considered some options for a domain which will enable us to demonstrate:
1. Chat without RAG
2. Chat with classic RAG
3. Agentic RAG
One design for a theme for the demo comes to mind that we can discuss.  We'll validate (or decide to use something else) and then we will dive deeper into tool additions for the agentic RAG part of the demo.  We have a commonly used demo app used for our AI lessons which is centered around pet owner assistance after a vet clinic visit.  We have referred to the app as "Pet Care Coach".  Here are some scenarios which will illustrate the three levels of context outlined above:
1. Chat without RAG: our fictional pet owner has a sick pet and chooses to try asking AI (say, ChatGPT) for help diagnosing a pet's condition based on a description of the symptoms.  In this case, the only context is whatever the user puts into the chat.
2. Chat with Classic RAG.  In this scenario, we'll imagine the pet owner takes their pet to the clinic and engages in a conversation with the vet about the symptoms they are seeing with their pet.  This clinic uses software which records and transcribes the complete interaction between pet owner and clinic staff (with the permission of all present).  This transcription provides quite a bit of context around what the pet owner has observed with their pet, along with any questions or advice provided by the vet.  Let's further suppose that the clinic software ingests this transcription into a vector store so that the vet can utilize it later through a RAG-empowered chat (perhaps to create SOAP notes).  In this situation, our demo app could show what a question/answer chat session would look like in this classic RAG environment.
3. Agentic RAG: Now we show how much agentic RAG can empower the users.  Let's say the clinic has inhouse diagnostic instruments and software which captures the results of tests the vet ran on the pet.  These results are recorded in a database.  Agentic RAG could both access the RAG content employed in the previous scenario, and directly access the test results in the database (along with any other tooling we come up with for the demo) to generate treatment advice.

What do you think of this set of scenarios for the demo?  I have the demo app from previous Promptly-at-9 session where we demonstrated chat with and without RAG (the app has a switch to turn on/off RAG as well as a means of ingesting new content for the vector database).  For reference, the app we would modify to accommodate the third scenario is here: https://github.com/terrytompkins/rag_hello_world



Great!  I like your suggestions around the framing of the narrative - let's go with that.  Here is how I would like to proceed: we're going to need to work on code, sample data and docs (e.g. diagnostic data and a pet owner/clinic staff transcript), and presentation materials.  I would like you to factor in everything we've described here and create a downloadable, detailed design document for altering the demo app (in markdown format) which is suitable for me to drop into Cursor and instruct it to make the corresponding adjustments to the code to implement the functionality.  The design should include (as you referenced) a schema for the SQLite database to hold the fictional results (say, realistic looking chem and/or blood test results which might have been requested based on the symptoms of the pet which we will also make up).  The schema should be fairly realistic so that we are also able to demonstrate natural language-to-SQL query generation as part of the chat/tooling.  The design should also include a simplistic data viewer which would allow us to peek at the diagnostic data to show the users what was factored into the agentic RAG process - or if there is a web-based tool I can download and run which allows me to view local SQLite data, then that would be fine as well.  I could pop out of the demo app and into another browser tab to show the data under the hood with such a tool.  Once you provide the design doc, I'll drop that into a branch in my existing demo app, and prompt Cursor to work through the code changes.  Then you and I can fabricate the data/docs referenced above.  Once that is done and I've tested that data in the demo app, I'll return and we can work on presentation materials.  sound like a plan?